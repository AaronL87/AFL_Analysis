{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AFL Time Series Data Analysis with Result and AFL Fantasy Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import ttest_ind, zscore\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#Supresses scientific notation\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"stats.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating \"Age\" column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting date objects to datetime:\n",
    "df['D.O.B'] = pd.to_datetime(df['D.O.B'], format='%Y'+'-'+'%m'+'-'+'%d')\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%Y'+'-'+'%m'+'-'+'%d')\n",
    "\n",
    "#Creating Age column:\n",
    "df.insert(2,'Age',(df['Date']-df['D.O.B'])/np.timedelta64(1,'Y'))\n",
    "\n",
    "df.drop('D.O.B',axis=1,inplace=True)\n",
    "\n",
    "#Changing WinLoss to numerical values\n",
    "df.WinLoss.replace(['W', 'L', 'D'],[1,0,.5],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing Null Values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing post season \"Rounds\" (they also have null values)\n",
    "round_list = ['QF', 'SF', 'PF', 'GF', 'EF']\n",
    "df = df[~df.Round.isin(round_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a alphabetically sorted \"Team, Opposition\" column to be able to group by game:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Teams'] = df[['Team','Opposition']].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Teams = df.Teams.apply(sorted).apply(', '.join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Points Per Percent Played column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating \"points per percent of game played\" columns\n",
    "df.insert(10, 'PointsPerPercentPlayed',(df['Goals']+df['Behinds'])/df['PercentPlayed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_list = df.select_dtypes(include=['number']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(6, 5)\n",
    "\n",
    "m=0\n",
    "for i in range(6):\n",
    "    for j in range(5):\n",
    "\n",
    "        df[number_list[m]].plot(kind='hist',bins=20,ax=ax[i,j],figsize=(30, 30),\n",
    "                                edgecolor='k').set_title(number_list[m])\n",
    "        m+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = df.set_index(['Season','Round']).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing all players by round:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_list = ['PointsPerPercentPlayed','Disposals', 'Kicks', 'Marks','Handballs',\n",
    "                'Goals', 'Behinds','Hitouts', 'Tackles', 'Rebound50s','Inside50s',\n",
    "                'Clearances','Clangers', 'FreesFor', 'FreesAgainst','BrownlowVotes',\n",
    "                'ContendedPossessions', 'UncontendedPossessions','ContestedMarks',\n",
    "                'MarksInside50', 'OnePercenters', 'Bounces', 'GoalAssists']\n",
    "\n",
    "normalize_list = ['Age', 'Height', 'Weight', 'Score', 'Margin']\n",
    "\n",
    "lose = ['Age', 'Height', 'Weight'] #For rows that I don't want to shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "templist=[]\n",
    "for col in scaling_list:\n",
    "    df_ML[col+'_n1'] = df_ML.groupby(['Season','Round'])[col].transform(lambda x:(x.astype(float) - min(x))/(max(x)-min(x)))    \n",
    "    templist.append(col+'_n1')\n",
    "\n",
    "scaling_list += templist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templist=[]\n",
    "for col in normalize_list:\n",
    "    df_ML[col+'_n1'] = df_ML.groupby(['Season','Round'])[col].transform(lambda x: zscore(x,ddof=1))\n",
    "    templist.append(col+'_n1')\n",
    "    \n",
    "    if col.startswith('Age')|col.startswith('Height')|col.startswith('Weight'):\n",
    "        lose.append(col+'_n1')\n",
    "\n",
    "normalize_list += templist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing further by game:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML = df_ML.set_index(['Teams'],append=1).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templist=[]\n",
    "for col in scaling_list:\n",
    "    df_ML[col+'_n2'] = df_ML.groupby(['Season','Round','Teams'])[col].transform(lambda x:(x.astype(float) - min(x))/(max(x)-min(x)))\n",
    "    templist.append(col+'_n2')\n",
    "\n",
    "scaling_list += templist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templist=[]\n",
    "for col in normalize_list:\n",
    "    df_ML[col+'_n2'] = df_ML.groupby(['Season','Round','Teams'])[col].transform(lambda x: zscore(x,ddof=1))\n",
    "    templist.append(col+'_n2')\n",
    "    \n",
    "    if col.startswith('Age')|col.startswith('Height')|col.startswith('Weight'):\n",
    "        lose.append(col+'_n2')\n",
    "\n",
    "normalize_list += templist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_ML.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing further by team:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML = df_ML.set_index(['Team'],append=1).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templist=[]\n",
    "for col in scaling_list:\n",
    "    df_ML[col+'_n3'] = df_ML.groupby(['Season','Round','Teams','Team'])[col].transform(lambda x:(x.astype(float) - min(x))/(max(x)-min(x)))\n",
    "    templist.append(col+'_n3')\n",
    "\n",
    "scaling_list += templist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templist=[]\n",
    "for col in normalize_list:\n",
    "    df_ML[col+'_n3'] = df_ML.groupby(['Season','Round','Teams','Team'])[col].transform(lambda x: zscore(x,ddof=1))\n",
    "    templist.append(col+'_n3')\n",
    "    \n",
    "    if col.startswith('Age')|col.startswith('Height')|col.startswith('Weight'):\n",
    "        lose.append(col+'_n3')\n",
    "    \n",
    "normalize_list += templist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing points made per percent of game to various characteristics relative to players in each game:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML.reset_index(inplace=True)\n",
    "df_ML.drop(['Season','Round'],axis=1,inplace=True)\n",
    "\n",
    "df_ML.set_index(['Date','Teams','Team'],inplace=True)\n",
    "df_ML.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the data by the percent played:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "templist=[]\n",
    "for col in scaling_list:\n",
    "    df_ML[col+'scale'] = df_ML[col].multiply(df_ML.PercentPlayed/100,axis=0)\n",
    "    templist.append(col+'scale')\n",
    "    \n",
    "scaling_list += templist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "number_list = scaling_list+normalize_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML[number_list] = df_ML[number_list].groupby(['Date','Teams','Team']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offsetting columns for time series analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML.reset_index(inplace=True)\n",
    "df_ML.drop(['Player','Position','PercentPlayed','Opposition','Teams'],axis=1,inplace=True)\n",
    "df_ML.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lose #Rows that I don't want to shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Offset_List = number_list + ['WinLoss']\n",
    "\n",
    "for x in lose:\n",
    "    Offset_List.remove(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PointsList=[]\n",
    "\n",
    "for column_name in Offset_List:\n",
    "    df_ML[column_name+'shift1'] = df_ML.set_index('Date',append=1).sort_index(level=1)\\\n",
    "        .groupby('Team')[column_name].shift().reset_index(['Date'], drop=1)\n",
    "\n",
    "    PointsList.append(column_name+'shift1')\n",
    "\n",
    "    for i in range(2,11):\n",
    "        df_ML[column_name+'shift'+str(i)] = df_ML.set_index('Date',append=1).sort_index(level=1)\\\n",
    "            .groupby('Team')[column_name].shift(i).reset_index(['Date'], drop=1)\n",
    "\n",
    "        df_ML[column_name+'avg'+str(i)] = df_ML.set_index('Date',append=1).sort_index(level=1)\\\n",
    "            .groupby('Team')[column_name].rolling(window=i,min_periods=i).mean()\\\n",
    "            .groupby('Team').shift().reset_index(['Team','Date'], drop=1)\n",
    "\n",
    "        PointsList.append(column_name+'shift'+str(i))\n",
    "        PointsList.append(column_name+'avg'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Offset_List.remove('WinLoss')\n",
    "\n",
    "df_ML.drop(Offset_List,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Fixing nulls again because of shifting:\n",
    "df_ML.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Win and Loss Distributions of Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML_win = df_ML.select_dtypes(include=['number'])[df_ML.WinLoss==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML_loss = df_ML.select_dtypes(include=['number'])[df_ML.WinLoss==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_list = df_ML_win.columns\n",
    "len(number_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking distribution differences between winners and losers via hypothesis testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_list=[]\n",
    "\n",
    "for m in range(7340):\n",
    "    test_stat1, p_value1 = ttest_ind(df_ML_win[number_list[m]], df_ML_loss[number_list[m]])\n",
    "    \n",
    "    series_list.append([number_list[m], test_stat1])\n",
    "\n",
    "df_stat = pd.DataFrame(series_list, columns=['column_name','test_stat_mean'])\n",
    "df_stat.set_index('column_name',inplace=True)\n",
    "df_stat.replace([np.inf, -np.inf], np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stat.dropna().abs().sort_values('test_stat_mean',ascending=False)['test_stat_mean'].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on the appearance of the distributions, it seems that the most important features in determining a win are Age, Brownlow Votes, Goal Assists, and previous Points per Percent Played. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning:\n",
    "## Making dummy variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_ML.select_dtypes(include=['object']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_list = df_ML.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML = pd.get_dummies(df_ML,columns=categorical_list,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML = df_ML[df_ML.WinLoss!=.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternating between dropping wins and losses to remove duplicate information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_list=[]\n",
    "for row in range(len(df_ML)):\n",
    "    if (row % 2!=0) & (df_ML.WinLoss.iloc[row]==0):\n",
    "        row_list.append(df_ML.index[row])\n",
    "    elif (row % 2==0) & (df_ML.WinLoss.iloc[row]!=0):\n",
    "        row_list.append(df_ML.index[row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML.drop(row_list,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML.WinLoss.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting Data and Creating Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_ML.drop(['WinLoss','Date'],axis=1)\n",
    "y = df_ML['WinLoss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "#for function below\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from time import time\n",
    "from sklearn.metrics import make_scorer,confusion_matrix,accuracy_score,\\\n",
    "    precision_score,recall_score,f1_score,roc_auc_score,matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_function(target,pred):\n",
    "    return accuracy_score(target, pred),precision_score(target, pred),\\\n",
    "        recall_score(target, pred),f1_score(target, pred),\\\n",
    "        roc_auc_score(target, pred),matthews_corrcoef(target, pred)\n",
    "\n",
    "def STRAT_TEST(clf,X_all,y_all,folds_num,row_factor):\n",
    "    start=time()\n",
    "    \n",
    "    SFLD=StratifiedKFold(n_splits=folds_num,random_state=0,shuffle=True)\n",
    "    print ('{}:'.format(clf.__class__.__name__),'\\n')\n",
    "    \n",
    "    acc_list_train=[]\n",
    "    acc_list_test=[]\n",
    "    prc_list_train=[]\n",
    "    prc_list_test=[]\n",
    "    rcal_list_train=[]\n",
    "    rcal_list_test=[]\n",
    "    f1_list_train=[]\n",
    "    f1_list_test=[]\n",
    "    matt_list_train=[]\n",
    "    matt_list_test=[]\n",
    "    AUC_list_train=[]\n",
    "    AUC_list_test=[]\n",
    "    \n",
    "    samp_size=X_all.shape[0]//row_factor\n",
    "    \n",
    "    for fold,(train_index,target_index) in enumerate(SFLD.split(X_all[:samp_size],\n",
    "                                                                y_all[:samp_size])):\n",
    "        X_train=X_all.iloc[train_index].values\n",
    "        y_train=y_all.iloc[train_index].values\n",
    "\n",
    "        X_test=X_all.iloc[target_index].values\n",
    "        y_test=y_all.iloc[target_index].values\n",
    "        \n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred1=clf.predict(X_train)\n",
    "        y_pred2=clf.predict(X_test)\n",
    "\n",
    "        train_acc,train_prc,train_rcal,train_f1,train_auc,train_matt=metrics_function(y_train,y_pred1)\n",
    "        \n",
    "        test_acc,test_prc,test_rcal,test_f1,test_auc,test_matt=metrics_function(y_test,y_pred2)\n",
    "        \n",
    "        acc_list_train.append(train_acc)\n",
    "        acc_list_test.append(test_acc)\n",
    "        prc_list_train.append(train_prc)\n",
    "        prc_list_test.append(test_prc)\n",
    "        rcal_list_train.append(train_rcal)\n",
    "        rcal_list_test.append(test_rcal)\n",
    "        \n",
    "        f1_list_train.append(train_f1)\n",
    "        f1_list_test.append(test_f1)\n",
    "        matt_list_train.append(train_matt)\n",
    "        matt_list_test.append(test_matt)\n",
    "        AUC_list_train.append(train_auc)\n",
    "        AUC_list_test.append(test_auc)\n",
    "    \n",
    "    print(\"Averages:\"'\\n')\n",
    "    \n",
    "    print(\"Train acc: {}, Test acc: {}\".format(np.mean(acc_list_train),\n",
    "                                               np.mean(acc_list_test)))\n",
    "    print(\"Train prc: {}, Test prc: {}\".format(np.mean(prc_list_train),\n",
    "                                               np.mean(prc_list_test)))\n",
    "    print(\"Train recall: {}, Test recall: {}\".format(np.mean(rcal_list_train),\n",
    "                                                     np.mean(rcal_list_test)),'\\n')\n",
    "    \n",
    "    print(\"Train f1: {}, Test f1: {}\".format(np.mean(f1_list_train),\n",
    "                                             np.mean(f1_list_test)))\n",
    "    print(\"Train MattCC: {}, Test MattCC: {}\".format(np.mean(matt_list_train),\n",
    "                                                     np.mean(matt_list_test)))\n",
    "    print(\"Train AUC: {}, Test AUC: {}\".format(np.mean(AUC_list_train),\n",
    "                                               np.mean(AUC_list_test)),'\\n'*2)\n",
    "        \n",
    "    print(\"Sample Size: {}, Folds Num: {}, Time: {}\".format(samp_size,folds_num,\n",
    "                                                            time()-start),'\\n'*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_A = LogisticRegression(penalty='l1',tol=1e-1,C=.15,solver='liblinear',random_state=0)\n",
    "\n",
    "clf_B = RandomForestClassifier(n_estimators=200,max_depth=3,max_features=.5,min_samples_split=35,\n",
    "                               min_samples_leaf=5,random_state=0)\n",
    "\n",
    "clf_C = xgb.XGBClassifier(n_estimators=200,max_depth=4,learning_rate=.05,gamma=9,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STRAT_TEST(clf_A, X, y, 7, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STRAT_TEST(clf_B, X, y, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STRAT_TEST(clf_C, X, y, 5, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previous win percentage of odds favorites from 2009-2013\n",
    "(according to https://www.bigfooty.com/forum/threads/how-often-do-favourites-win.1004437/)\n",
    "\n",
    "##### In 2009 it was 50/72 or 69.4% - (only data available)\n",
    "##### In 2010 it was 109/176 or 61.9%\n",
    "##### In 2011 it was 142/187 or 75.9%\n",
    "##### In 2012 it was 155/198 or 78.2%\n",
    "##### So far in 2013 it was 41/54 or 75.9%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting AFL Fantasy points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_F = df.copy()\n",
    "fantasy_points = {'Kicks':3,'Handballs':2,'Marks':3,'Tackles':4,'FreesFor':1,\n",
    "                  'FreesAgainst':-3,'Hitouts':1,'Goals':6,'Behinds':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list=[]\n",
    "\n",
    "#Creating fantasy columns\n",
    "for keys in fantasy_points.keys():\n",
    "    df_F[keys+'_fantasy'] = df_F[keys]*fantasy_points[keys]\n",
    "    new_list.append(keys+'_fantasy')\n",
    "    \n",
    "df_F['fantasy_points'] = pd.Series()   \n",
    "    \n",
    "for cols in fantasy_points.keys():\n",
    "    df_F.fantasy_points = df_F.fantasy_points.add(df_F[cols+'_fantasy'],fill_value=0)\n",
    "\n",
    "df_F['target'] = df_F.fantasy_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_F[new_list+['fantasy_points']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_F.insert(11, 'FantasyPerPercentPlayed',df_F['fantasy_points']/df_F['PercentPlayed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_scaling_list = ['PointsPerPercentPlayed','Disposals', 'Kicks', 'Marks','Handballs',\n",
    "                    'Goals', 'Behinds','Hitouts', 'Tackles', 'Rebound50s','Inside50s',\n",
    "                    'Clearances','Clangers', 'FreesFor', 'FreesAgainst','BrownlowVotes',\n",
    "                    'ContendedPossessions', 'UncontendedPossessions','ContestedMarks',\n",
    "                    'MarksInside50', 'OnePercenters', 'Bounces', 'GoalAssists']\n",
    "\n",
    "new_normalize_list = ['Age', 'Height', 'Weight', 'Score', 'Margin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_F.drop(new_list,axis=1,inplace=True)\n",
    "new_scaling_list = new_scaling_list + ['fantasy_points'] + ['FantasyPerPercentPlayed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fantasy points by position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_F.Position.value_counts())\n",
    "\n",
    "hist_names = df_F.Position.value_counts().index.drop('Midfield, Ruck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for names in hist_names:\n",
    "    print(names+':','\\n')\n",
    "    print(df_F[df_F.Position==names].fantasy_points.describe(),'\\n'*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is a commonly held belief that, in AFL Fantasy, midfielders are the best position for points, and this information confirms that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing all players by round:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "templist=[]\n",
    "for col in new_scaling_list:\n",
    "    df_F[col+'_n1'] = df_F.groupby(['Season','Round'])[col].transform(lambda x:(x.astype(float) - min(x))/(max(x)-min(x)))    \n",
    "    templist.append(col+'_n1')\n",
    "\n",
    "new_scaling_list += templist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templist=[]\n",
    "for col in new_normalize_list:\n",
    "    df_F[col+'_n1'] = df_F.groupby(['Season','Round'])[col].transform(lambda x: zscore(x,ddof=1))\n",
    "    templist.append(col+'_n1')\n",
    "\n",
    "new_normalize_list += templist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing further by game:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_F = df_F.set_index(['Teams'],append=1).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templist=[]\n",
    "for col in new_scaling_list:\n",
    "    df_F[col+'_n2'] = df_F.groupby(['Season','Round','Teams'])[col].transform(lambda x:(x.astype(float) - min(x))/(max(x)-min(x)))\n",
    "    templist.append(col+'_n2')\n",
    "\n",
    "new_scaling_list += templist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templist=[]\n",
    "for col in new_normalize_list:\n",
    "    df_F[col+'_n2'] = df_F.groupby(['Season','Round','Teams'])[col].transform(lambda x: zscore(x,ddof=1))\n",
    "    templist.append(col+'_n2')\n",
    "\n",
    "new_normalize_list += templist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_F.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing further by team:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_F = df_F.set_index(['Team'],append=1).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templist=[]\n",
    "for col in new_scaling_list:\n",
    "    df_F[col+'_n3'] = df_F.groupby(['Season','Round','Teams','Team'])[col].transform(lambda x:(x.astype(float) - min(x))/(max(x)-min(x)))\n",
    "    templist.append(col+'_n3')\n",
    "\n",
    "new_scaling_list += templist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templist=[]\n",
    "for col in new_normalize_list:\n",
    "    df_F[col+'_n3'] = df_F.groupby(['Season','Round','Teams','Team'])[col].transform(lambda x: zscore(x,ddof=1))\n",
    "    templist.append(col+'_n3')\n",
    "    \n",
    "new_normalize_list += templist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_F.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limiting the size of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_F.reset_index(inplace=True)\n",
    "df_F = df_F[(df_F.Season==2015)|(df_F.Season==2016)|(df_F.Season==2017)|(df_F.Season==2018)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing points made per percent of game to various characteristics relative to players in each game:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_F.drop(['Season','Round'],axis=1,inplace=True)\n",
    "\n",
    "df_F = df_F.set_index(['Date','Teams','Team']).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the data by the percent played:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "templist=[]\n",
    "for col in new_scaling_list:\n",
    "    df_F[col+'scale'] = df_F[col].multiply(df_F.PercentPlayed/100,axis=0)\n",
    "    templist.append(col+'scale')\n",
    "    \n",
    "new_scaling_list += templist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_number_list = new_scaling_list+new_normalize_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offsetting columns for time series analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_F.reset_index(inplace=True)\n",
    "df_F.drop(['Teams','PercentPlayed'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Offset_Fantasy_List = new_number_list + ['WinLoss']\n",
    "\n",
    "for x in lose:\n",
    "    Offset_Fantasy_List.remove(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FantasyList=[]\n",
    "\n",
    "for column_name in Offset_Fantasy_List:\n",
    "    df_F[column_name+'shift1'] = df_F.set_index('Date',append=1).sort_index(level=1)\\\n",
    "        .groupby('Player')[column_name].shift().reset_index(['Date'], drop=1)\n",
    "\n",
    "    FantasyList.append(column_name+'shift1')\n",
    "\n",
    "    for i in range(2,11):\n",
    "        df_F[column_name+'shift'+str(i)] = df_F.set_index('Date',append=1).sort_index(level=1)\\\n",
    "            .groupby('Player')[column_name].shift(i).reset_index(['Date'], drop=1)\n",
    "        \n",
    "        df_F[column_name+'avg'+str(i)] = df_F.set_index('Date',append=1).sort_index(level=1)\\\n",
    "            .groupby('Player')[column_name].rolling(window=i,min_periods=i).mean()\\\n",
    "            .groupby('Player').shift().reset_index(['Player','Date'], drop=1)\n",
    "\n",
    "        FantasyList.append(column_name+'shift'+str(i))\n",
    "        FantasyList.append(column_name+'avg'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_F.drop(Offset_Fantasy_List,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = df_F.select_dtypes(include=['number']).drop('target',axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixing nulls again because of shifting:\n",
    "df_F.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Between AFL Fantasy Points and Other Features by Position:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defender:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_F[df_F.Position=='Defender'][column_list].corrwith(df_F[df_F.Position=='Defender'].target).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_F[df_F.Position=='Forward'][column_list].corrwith(df_F[df_F.Position=='Forward'].target).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Midfield:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_F[df_F.Position=='Midfield'][column_list].corrwith(df_F[df_F.Position=='Midfield'].target).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Midfield, Forward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_F[df_F.Position=='Midfield, Forward'][column_list].corrwith(df_F[df_F.Position=='Midfield, Forward'].target).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ruck:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_F[df_F.Position=='Ruck'][column_list].corrwith(df_F[df_F.Position=='Ruck'].target).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward, Ruck:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_F[df_F.Position=='Forward, Ruck'][column_list].corrwith(df_F[df_F.Position=='Forward, Ruck'].target).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defender, Midfield:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_F[df_F.Position=='Defender, Midfield'][column_list].corrwith(df_F[df_F.Position=='Defender, Midfield'].target).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defender, Forward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_F[df_F.Position=='Defender, Forward'][column_list].corrwith(df_F[df_F.Position=='Defender, Forward'].target).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning:\n",
    "## Making dummy variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_F.select_dtypes(include=['object']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_list2 = df_F.select_dtypes(include=['object']).drop('Player',axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_F = pd.get_dummies(df_F,columns=categorical_list2,drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting Data and Creating Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = df_F.drop(['target','Date','Player'],axis=1)\n",
    "y2 = df_F['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import SGDRegressor,Ridge\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_A = SGDRegressor(random_state=0)\n",
    "\n",
    "clf_B = Ridge(random_state=0)\n",
    "\n",
    "clf_C = LinearSVR(random_state=0)\n",
    "\n",
    "clf_D = RandomForestRegressor(random_state=0,max_depth=7)\n",
    "\n",
    "clf_E = MLPRegressor(random_state=0,alpha=0.1)\n",
    "\n",
    "clf_F = xgb.XGBRegressor(random_state=0,max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_function(target,pred):\n",
    "    return r2_score(target, pred)\n",
    "\n",
    "def FOLD_TEST(clf,X_all,y_all,folds_num,row_factor):\n",
    "    start=time()\n",
    "    \n",
    "    KFLD=KFold(n_splits=folds_num,random_state=0,shuffle=True)\n",
    "    print ('{}:'.format(clf.__class__.__name__),'\\n')\n",
    "    \n",
    "    samp_size=X_all.shape[0]//row_factor\n",
    "    \n",
    "    R2_list_train=[]\n",
    "    R2_list_test=[]\n",
    "    \n",
    "    for fold,(train_index,target_index) in enumerate(KFLD.split(X_all[:samp_size],\n",
    "                                                                y_all[:samp_size])):\n",
    "        X_train=X_all.iloc[train_index].values\n",
    "        y_train=y_all.iloc[train_index].values\n",
    "\n",
    "        X_test=X_all.iloc[target_index].values\n",
    "        y_test=y_all.iloc[target_index].values\n",
    "        \n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred1=clf.predict(X_train)\n",
    "        y_pred2=clf.predict(X_test)\n",
    "\n",
    "        train_R2=metrics_function(y_train,y_pred1)\n",
    "        test_R2=metrics_function(y_test,y_pred2)\n",
    "        \n",
    "        R2_list_train.append(train_R2)\n",
    "        R2_list_test.append(test_R2)\n",
    "   \n",
    "    print(\"Train R2: {}, Test R2: {}\".format(np.mean(R2_list_train),\n",
    "                                             np.mean(R2_list_test)),'\\n'*2)   \n",
    "        \n",
    "    print(\"Sample Size: {}, Folds Num: {}, Time: {}\".format(samp_size,folds_num,\n",
    "                                                            time()-start),'\\n'*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD_TEST(clf_A, X2, y2, 5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD_TEST(clf_B, X2, y2, 5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD_TEST(clf_C, X2, y2, 5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD_TEST(clf_D, X2, y2, 5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD_TEST(clf_E, X2, y2, 5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD_TEST(clf_F, X2, y2, 5, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
